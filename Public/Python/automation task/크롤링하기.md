# 크롤링

## 기본 세팅

1. 크롬 드라이버 다운로드
   https://chromedriver.chromium.org/downloads에 접속하여 크롬버전과 같은 것을 다운로드 한다.

2. 드라이버 PATH 위치로 이동 (PATH default location : /usr/local/bin )

   ```bash
   $ sudo mv chromedriver /usr/local/bin
   ```

3. selenium 설치

   ```bash
   $ pip3 install selenium
   ```

4. 크롬 드라이버 실행

   ```python
   from selenium import webdriver
   
   driver = webdriver.Chrome('/usr/local/bin/chromedriver')
   driver.get("https://google.com") # 해당 url로 이동
   ```

5. (Optional) Headless 모드로 실행하려면

   ```python
   # __init__에 추가
   self.options.add_argument("headless")
   # 가끔 headless를 막는 경우가 있다. 
   # Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/60.0.3112.50 Safari/537.36
   # 위와 같이 user-agent에서 headless임을 표시해주는 친절한 크롬 때문에 막힐 수 있다.
   # 이럴 땐 가짜 user-agent를 옵션에 걸어주면 된다.
   self.options.add_argument("user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36")
   ```

   

## 크롤러 세팅

- `find_element_xxx(data)` : HTML tag를 찾아준다.

  ```python
  ps_input = driver.find_element_by_name("Hi")
  #find_element의 종류는 다양하다. 상황에 따라 사용하자.
  
  ps_input2 = driver.find_element_by_xpath(<xpath>)
  #xpath는 크롬 개발자도구에서 태그선택후 오른쪽 마우스 클릭 -> copy -> xpath를 누르면 알 수 있다.
  ```
  
  - `.text` : Tag 내부 value
  
    ```python
    # <div name="Hi">Bye</div>
    ps_input = driver.find_element_by_name("Hi").text
    # => Bye
    ```
  
  - `send_keys(value)` : 값을 입력
  
    ```python
    ps_input.send_keys('aaa')
    ```
  
  - `get_attribute(value)` : 속성값을 찾음
  
    ```python
    a_tag = driver.find_element_by_tag('a')
    
    a_tag.get_attribute('href')
    ```
  
  - `click()` : 클릭
  
- `keys` : 키

  ```python
  from selenium.webdriver.common.keys import Keys
  
  ps_input.send_keys(Keys.RETURN) # 엔터키를 입력
  ```



## 데이터 가공

- BeautifulSoup 설치

  ```bash
  pip3 install beautifulsoup4
  ```

### html 추출

```python
from bs4 import BeautifulSoup

html = self.driver.page_source
# 현재 페이지의 html 소스

soup = BeautifulSoup(html, 'html.parser')
```

### BeautifulSoup

- `find` : 원하는 태그를 찾음 (1개)

  ```python
  soup.find("p")
  soup.find(class_="test")
  soup.find(attrs = {'class':'test'})
  soup.find("p", class_"test)
  ```

- `find_all`, `findAll` : 원하는 태그를 모두 찾음 (여러개)

  ```python
  soup.find_all("p")
  soup.find_all(class_="test")
  soup.find_all(attrs = {'class':'test'})
  soup.find_all("p", class_"test)
  ```

  - 겹쳐서 사용 가능하다.

    ```python
    soup.find_all("p").find("table")
    ```

- `select_one` : CSS selector로 원하는 태그를 찾음 (1개)

  ```python
  soup.select_one("p")
  soup.select_one(".test")
  soup.select_one("p.test")
  soup.select_one("#hi")
  soup.select_one("p.test#hi")
  ```

- `select` : CSS selector로 원하는 태그를 모두 찾음 (여러개)

  ```
  soup.select("p")
  soup.select(".test")
  soup.select("p.test")
  soup.select("#hi")
  soup.select("p.test#hi")
  ```

  - `find`와 달리 겹칠 필요 없다.

    ```
    soup.select("p > .test2 > div > #hello > table")
    ```

    

